{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b546d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51118a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下載 nltk 資源（只需一次）\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fa7edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "dataset = datasets.load_from_disk(\"super-emotion\")\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "texts_train  = train_dataset[\"text\"]\n",
    "labels_train = train_dataset[\"labels_str\"]\n",
    "\n",
    "texts_test = test_dataset[\"text\"]\n",
    "labels_test = test_dataset[\"labels_str\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb44aa72",
   "metadata": {},
   "source": [
    "### Data Preprocessing(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ce5a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK prerocessing\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t.isalpha()]  # 移除標點、數字\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "#RAM會爆炸!!\n",
    "texts_cleaned_train = [preprocess_text(t) for t in texts_train [:50000]]\n",
    "texts_cleaned_test = [preprocess_text(t) for t in texts_test [:50000]]\n",
    "labels_subset_train = labels_train[:50000]\n",
    "labels_subset_test = labels_test[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c0553fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 向量化\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "# X = vectorizer.fit_transform(texts_cleaned_train).toarray().astype(np.float32)\n",
    "X_train = vectorizer.fit_transform(texts_cleaned_train).toarray().astype(np.float32)\n",
    "X_test = vectorizer.transform(texts_cleaned_test).toarray().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5a6e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label multi-hot encoding\n",
    "mlb = MultiLabelBinarizer()\n",
    "# Y = mlb.fit_transform(labels_subset_train)   # shape = (n_samples, n_emotions)\n",
    "y_train = mlb.fit_transform(labels_subset_train)\n",
    "y_test = mlb.transform(labels_subset_test)\n",
    "\n",
    "# 分割訓練集與測試集\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8652a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立模型\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model=nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71bb329c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/75], Loss: 1.9463, Acc: 0.2447\n",
      "Epoch [2/75], Loss: 1.9439, Acc: 0.2447\n",
      "Epoch [3/75], Loss: 1.9414, Acc: 0.2447\n",
      "Epoch [4/75], Loss: 1.9385, Acc: 0.2447\n",
      "Epoch [5/75], Loss: 1.9352, Acc: 0.2448\n",
      "Epoch [6/75], Loss: 1.9315, Acc: 0.2463\n",
      "Epoch [7/75], Loss: 1.9275, Acc: 0.2522\n",
      "Epoch [8/75], Loss: 1.9232, Acc: 0.2698\n",
      "Epoch [9/75], Loss: 1.9187, Acc: 0.3038\n",
      "Epoch [10/75], Loss: 1.9141, Acc: 0.3502\n",
      "Epoch [11/75], Loss: 1.9092, Acc: 0.4129\n",
      "Epoch [12/75], Loss: 1.9041, Acc: 0.4808\n",
      "Epoch [13/75], Loss: 1.8988, Acc: 0.5468\n",
      "Epoch [14/75], Loss: 1.8935, Acc: 0.5983\n",
      "Epoch [15/75], Loss: 1.8878, Acc: 0.6414\n",
      "Epoch [16/75], Loss: 1.8820, Acc: 0.6734\n",
      "Epoch [17/75], Loss: 1.8759, Acc: 0.6974\n",
      "Epoch [18/75], Loss: 1.8698, Acc: 0.7133\n",
      "Epoch [19/75], Loss: 1.8633, Acc: 0.7273\n",
      "Epoch [20/75], Loss: 1.8567, Acc: 0.7345\n",
      "Epoch [21/75], Loss: 1.8498, Acc: 0.7409\n",
      "Epoch [22/75], Loss: 1.8428, Acc: 0.7478\n",
      "Epoch [23/75], Loss: 1.8356, Acc: 0.7507\n",
      "Epoch [24/75], Loss: 1.8279, Acc: 0.7529\n",
      "Epoch [25/75], Loss: 1.8205, Acc: 0.7531\n",
      "Epoch [26/75], Loss: 1.8125, Acc: 0.7541\n",
      "Epoch [27/75], Loss: 1.8044, Acc: 0.7586\n",
      "Epoch [28/75], Loss: 1.7960, Acc: 0.7577\n",
      "Epoch [29/75], Loss: 1.7873, Acc: 0.7606\n",
      "Epoch [30/75], Loss: 1.7787, Acc: 0.7612\n",
      "Epoch [31/75], Loss: 1.7698, Acc: 0.7636\n",
      "Epoch [32/75], Loss: 1.7606, Acc: 0.7607\n",
      "Epoch [33/75], Loss: 1.7512, Acc: 0.7603\n",
      "Epoch [34/75], Loss: 1.7415, Acc: 0.7607\n",
      "Epoch [35/75], Loss: 1.7315, Acc: 0.7617\n",
      "Epoch [36/75], Loss: 1.7217, Acc: 0.7610\n",
      "Epoch [37/75], Loss: 1.7113, Acc: 0.7604\n",
      "Epoch [38/75], Loss: 1.7010, Acc: 0.7608\n",
      "Epoch [39/75], Loss: 1.6903, Acc: 0.7607\n",
      "Epoch [40/75], Loss: 1.6793, Acc: 0.7609\n",
      "Epoch [41/75], Loss: 1.6687, Acc: 0.7616\n",
      "Epoch [42/75], Loss: 1.6569, Acc: 0.7618\n",
      "Epoch [43/75], Loss: 1.6457, Acc: 0.7608\n",
      "Epoch [44/75], Loss: 1.6340, Acc: 0.7615\n",
      "Epoch [45/75], Loss: 1.6223, Acc: 0.7627\n",
      "Epoch [46/75], Loss: 1.6103, Acc: 0.7628\n",
      "Epoch [47/75], Loss: 1.5981, Acc: 0.7608\n",
      "Epoch [48/75], Loss: 1.5858, Acc: 0.7616\n",
      "Epoch [49/75], Loss: 1.5731, Acc: 0.7630\n",
      "Epoch [50/75], Loss: 1.5608, Acc: 0.7624\n",
      "Epoch [51/75], Loss: 1.5482, Acc: 0.7632\n",
      "Epoch [52/75], Loss: 1.5344, Acc: 0.7641\n",
      "Epoch [53/75], Loss: 1.5216, Acc: 0.7637\n",
      "Epoch [54/75], Loss: 1.5091, Acc: 0.7645\n",
      "Epoch [55/75], Loss: 1.4953, Acc: 0.7648\n",
      "Epoch [56/75], Loss: 1.4826, Acc: 0.7638\n",
      "Epoch [57/75], Loss: 1.4685, Acc: 0.7649\n",
      "Epoch [58/75], Loss: 1.4557, Acc: 0.7656\n",
      "Epoch [59/75], Loss: 1.4409, Acc: 0.7671\n",
      "Epoch [60/75], Loss: 1.4284, Acc: 0.7661\n",
      "Epoch [61/75], Loss: 1.4140, Acc: 0.7684\n",
      "Epoch [62/75], Loss: 1.4010, Acc: 0.7693\n",
      "Epoch [63/75], Loss: 1.3860, Acc: 0.7681\n",
      "Epoch [64/75], Loss: 1.3726, Acc: 0.7681\n",
      "Epoch [65/75], Loss: 1.3591, Acc: 0.7692\n",
      "Epoch [66/75], Loss: 1.3449, Acc: 0.7699\n",
      "Epoch [67/75], Loss: 1.3310, Acc: 0.7729\n",
      "Epoch [68/75], Loss: 1.3173, Acc: 0.7709\n",
      "Epoch [69/75], Loss: 1.3043, Acc: 0.7731\n",
      "Epoch [70/75], Loss: 1.2889, Acc: 0.7743\n",
      "Epoch [71/75], Loss: 1.2754, Acc: 0.7739\n",
      "Epoch [72/75], Loss: 1.2621, Acc: 0.7743\n",
      "Epoch [73/75], Loss: 1.2473, Acc: 0.7760\n",
      "Epoch [74/75], Loss: 1.2348, Acc: 0.7743\n",
      "Epoch [75/75], Loss: 1.2213, Acc: 0.7774\n"
     ]
    }
   ],
   "source": [
    "#設定類別的權重，因為資料集不平衡\n",
    "class_counts = torch.tensor([ 5459,  4018, 12158,  2699,  3710,  9814,  2142],dtype=torch.float32)\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights = class_weights / class_weights.sum()*7\n",
    "#設定參數\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 128\n",
    "output_dim = y_train.shape[1]\n",
    "#初始化模型\n",
    "model = MLP(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#訓練模型\n",
    "epochs = 75\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    y_train_class = y_train.argmax(dim=1)\n",
    "    loss = criterion(outputs, y_train_class)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = accuracy_score(y_train_class.numpy(), preds.numpy())\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, Acc: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a67e550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.4131, Test Acc: 0.6878\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    y_test_class = y_test.argmax(dim=1)\n",
    "    test_loss = criterion(outputs, y_test_class)\n",
    "    preds = torch.argmax(outputs, dim=1)\n",
    "    test_acc = accuracy_score(y_test_class.numpy(), preds.numpy())\n",
    "    print(f\"Test Loss: {test_loss.item():.4f}, Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbb1494",
   "metadata": {},
   "source": [
    "### Data preprocessing(sklearning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cd036ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK prerocessing\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t.isalpha()]  # 移除標點、數字\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "texts_cleaned_train = [preprocess_text(t) for t in texts_train]\n",
    "texts_cleaned_test = [preprocess_text(t) for t in texts_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46ae8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 向量化\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "# X = vectorizer.fit_transform(texts_cleaned_train)\n",
    "X_train = vectorizer.fit_transform(texts_cleaned_train)\n",
    "X_test = vectorizer.transform(texts_cleaned_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfe2fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label multi-hot encoding\n",
    "mlb = MultiLabelBinarizer()\n",
    "# Y = mlb.fit_transform(labels_train)   \n",
    "y_train = mlb.fit_transform(labels_train) # shape = (n_samples, n_emotions)\n",
    "y_test = mlb.transform(labels_test)\n",
    "\n",
    "# 分割訓練集與測試集\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98c72638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.90      0.65      0.76      8705\n",
      "        Fear       0.86      0.65      0.74      6474\n",
      "         Joy       0.90      0.78      0.84     18484\n",
      "        Love       0.78      0.52      0.62      6157\n",
      "     Neutral       0.60      0.24      0.34      3925\n",
      "     Sadness       0.92      0.82      0.87     14853\n",
      "    Surprise       0.74      0.40      0.52      2660\n",
      "\n",
      "   micro avg       0.88      0.68      0.77     61258\n",
      "   macro avg       0.82      0.58      0.67     61258\n",
      "weighted avg       0.86      0.68      0.75     61258\n",
      " samples avg       0.69      0.70      0.69     61258\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wayne777aa/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "sklearn_model=LogisticRegression(max_iter=1000)\n",
    "clf= OneVsRestClassifier(sklearn_model)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "clf.fit(X_train, y_train)\n",
    "print(classification_report(y_test, y_pred, target_names=mlb.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
