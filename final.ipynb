{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b546d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51118a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下載 nltk 資源（只需一次）\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fa7edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "dataset = datasets.load_from_disk(\"super-emotion\")\n",
    "train_dataset = dataset[\"train\"]\n",
    "\n",
    "texts = train_dataset[\"text\"]\n",
    "labels = train_dataset[\"labels_str\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb44aa72",
   "metadata": {},
   "source": [
    "### Data Preprocessing(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce5a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK prerocessing\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t.isalpha()]  # 移除標點、數字\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "texts_cleaned = [preprocess_text(t) for t in texts[:50000]]\n",
    "labels_subset = labels[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0553fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 向量化\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X = vectorizer.fit_transform(texts_cleaned).toarray().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label multi-hot encoding\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(labels_subset)   # shape = (n_samples, n_emotions)\n",
    "\n",
    "# 分割訓練集與測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8652a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立模型\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model=nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#設定參數\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 128\n",
    "output_dim = len(set(y_train.numpy()))\n",
    "#初始化模型\n",
    "model = MLP(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#訓練模型\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbb1494",
   "metadata": {},
   "source": [
    "### Data preprocessing(sklearning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd036ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK prerocessing\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t.isalpha()]  # 移除標點、數字\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "texts_cleaned = [preprocess_text(t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ae8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 向量化\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X = vectorizer.fit_transform(texts_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe2fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label multi-hot encoding\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(labels)   # shape = (n_samples, n_emotions)\n",
    "\n",
    "# 分割訓練集與測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
